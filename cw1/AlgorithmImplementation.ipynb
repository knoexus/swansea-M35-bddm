{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    ds = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        filereader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in filereader:\n",
    "            ds.append(tuple(sorted(row[:-1])))\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Butter', 'Cheese', 'Coffee Powder', 'Ghee', 'Lassi', 'Yougurt'), ('Coffee Powder', 'Ghee'), ('Butter', 'Cheese', 'Lassi', 'Tea Powder'), ('Bread', 'Butter', 'Cheese', 'Coffee Powder', 'Panner', 'Tea Powder'), ('Butter', 'Cheese', 'Coffee Powder', 'Sugar', 'Sweet', 'Yougurt')]\n"
     ]
    }
   ],
   "source": [
    "read = read_file('GroceryStore.csv')[:5]\n",
    "print(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',')\n",
    "        for row in data:\n",
    "            filewriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support_count(instance, data, is_set):\n",
    "    count = 0\n",
    "    if is_set:\n",
    "        for row in data:\n",
    "            if set(instance).issubset(set(row)): \n",
    "                count = count + 1\n",
    "    else:\n",
    "        for row in data:\n",
    "            if instance in row:\n",
    "                count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support(data, items):\n",
    "    dct = {}\n",
    "    lgtn = len(data)\n",
    "    if isinstance(items, set): \n",
    "        for i in items:\n",
    "            support_count = calculate_support_count(i, data, True)\n",
    "            dct[i] = support_count / lgtn\n",
    "    else: \n",
    "        for i in items:\n",
    "            support_count = calculate_support_count(i, data, False)\n",
    "            dct[i] = support_count / lgtn\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_elimination(data, items, minimal_support):\n",
    "    dct = calculate_support(data, items)\n",
    "    support_resistant = []\n",
    "    for key in dct:\n",
    "        if dct[key] >= minimal_support:\n",
    "            support_resistant.append(key)\n",
    "    return support_resistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_level_one(data, sort_by_support_desc):\n",
    "    dct = defaultdict(int)\n",
    "    for y in data:\n",
    "        for x in y:\n",
    "            dct[x] += 1\n",
    "    if sort_by_support_desc:\n",
    "        return tuple([i for i in dict(sorted(dct.items(), key=lambda item: item[1], reverse=True))])\n",
    "    else:\n",
    "        return tuple(sorted([i for i in dct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bread',\n",
       " 'Butter',\n",
       " 'Cheese',\n",
       " 'Coffee Powder',\n",
       " 'Ghee',\n",
       " 'Lassi',\n",
       " 'Milk',\n",
       " 'Panner',\n",
       " 'Sugar',\n",
       " 'Sweet',\n",
       " 'Tea Powder',\n",
       " 'Yougurt']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_file('GroceryStore.csv')\n",
    "unique = find_unique_level_one(data, False)\n",
    "support_elimination(data, unique, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_fk1_1(previous_step_f_itemset, step_one_f_itemset):\n",
    "    lst = []\n",
    "    if isinstance(previous_step_f_itemset[0], list) or isinstance(previous_step_f_itemset[0], tuple): \n",
    "        for i in previous_step_f_itemset:\n",
    "            for k in step_one_f_itemset:\n",
    "                if k not in i:\n",
    "                    lst.append(tuple(sorted([*i, k])))\n",
    "    else:\n",
    "        for i in previous_step_f_itemset:\n",
    "            for k in step_one_f_itemset:\n",
    "                if k != i:\n",
    "                    lst.append(tuple(sorted((i, k))))\n",
    "    return set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Lassi', 'Panner'), ('Bread', 'Cheese'), ('Bread', 'Yougurt'), ('Coffee Powder', 'Yougurt'), ('Ghee', 'Yougurt'), ('Panner', 'Sugar'), ('Bread', 'Butter'), ('Bread', 'Sweet'), ('Bread', 'Tea Powder'), ('Bread', 'Panner'), ('Cheese', 'Sugar'), ('Coffee Powder', 'Sweet'), ('Butter', 'Sugar'), ('Ghee', 'Sweet'), ('Ghee', 'Tea Powder'), ('Milk', 'Yougurt'), ('Coffee Powder', 'Panner'), ('Ghee', 'Panner'), ('Tea Powder', 'Yougurt'), ('Coffee Powder', 'Tea Powder'), ('Cheese', 'Milk'), ('Butter', 'Milk'), ('Milk', 'Sweet'), ('Lassi', 'Sugar'), ('Milk', 'Panner'), ('Sugar', 'Yougurt'), ('Sweet', 'Yougurt'), ('Lassi', 'Milk'), ('Milk', 'Tea Powder'), ('Cheese', 'Ghee'), ('Butter', 'Ghee'), ('Cheese', 'Coffee Powder'), ('Sugar', 'Sweet'), ('Cheese', 'Lassi'), ('Sweet', 'Tea Powder'), ('Butter', 'Lassi'), ('Butter', 'Coffee Powder'), ('Sugar', 'Tea Powder'), ('Panner', 'Yougurt'), ('Bread', 'Sugar'), ('Bread', 'Milk'), ('Coffee Powder', 'Sugar'), ('Ghee', 'Sugar'), ('Butter', 'Cheese'), ('Cheese', 'Yougurt'), ('Ghee', 'Milk'), ('Panner', 'Sweet'), ('Butter', 'Yougurt'), ('Coffee Powder', 'Milk'), ('Milk', 'Sugar'), ('Panner', 'Tea Powder'), ('Cheese', 'Sweet'), ('Bread', 'Ghee'), ('Butter', 'Sweet'), ('Bread', 'Lassi'), ('Bread', 'Coffee Powder'), ('Cheese', 'Panner'), ('Lassi', 'Yougurt'), ('Butter', 'Panner'), ('Cheese', 'Tea Powder'), ('Coffee Powder', 'Ghee'), ('Butter', 'Tea Powder'), ('Coffee Powder', 'Lassi'), ('Ghee', 'Lassi'), ('Lassi', 'Sweet'), ('Lassi', 'Tea Powder')} "
     ]
    }
   ],
   "source": [
    "print(generate_candidates_fk1_1(unique, unique), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_algorigth(filename, max_length, min_support):\n",
    "    data = read_file(filename)\n",
    "    one_unique = find_unique_level_one(data, False)\n",
    "    el_one_unique = support_elimination(data, one_unique, min_support)\n",
    "    lim = 1\n",
    "    el_k_unique = el_one_unique\n",
    "    while(lim < max_length):\n",
    "        k_unique = generate_candidates_fk1_1(el_k_unique, el_one_unique)\n",
    "        el_k_unique = support_elimination(data, k_unique, min_support)\n",
    "        lim = lim + 1\n",
    "    return el_k_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = apriori_algorigth('GroceryStore.csv', max_length=4, min_support=0.048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(a, f'Result-{datetime.datetime.now()}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rule_props(itemset, data):\n",
    "    T = len(data)\n",
    "    support_count_dict = {}\n",
    "    gen_dict = {}\n",
    "    for item in itemset:\n",
    "        if item not in support_count_dict:\n",
    "            support_count_dict[item] = calculate_support_count(item, data, True)\n",
    "        all_subsets = chain.from_iterable(combinations(item, i) for i in range(1, len(item)))\n",
    "        for a in all_subsets:\n",
    "            if a not in support_count_dict:\n",
    "                support_count_dict[a] = calculate_support_count(a, data, True)\n",
    "            diff = tuple(set(item).difference(set(a)))\n",
    "            if not (a, diff) in gen_dict:\n",
    "                gen_dict[(a, diff)] = {\n",
    "                    'support': support_count_dict[item] / T,\n",
    "                    'confidence': support_count_dict[item] / support_count_dict[a]\n",
    "                }\n",
    "    return gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rule(min_support, min_confidence, data_file_name, frequent_file_name):\n",
    "    data = read_file(data_file_name)\n",
    "    frequent = read_file(frequent_file_name)\n",
    "    characteristics = association_rule_props(frequent, data)\n",
    "    return {k: v for k, v in characteristics.items() if v['support'] >= min_support and v['confidence'] >= min_confidence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('Lassi', 'Panner'), ('Sweet',)): {'support': 0.10098994092288041,\n",
       "  'confidence': 0.5066079295154186},\n",
       " (('Lassi', 'Sweet'), ('Panner',)): {'support': 0.10098994092288041,\n",
       "  'confidence': 0.49107142857142855},\n",
       " (('Panner', 'Sweet'), ('Lassi',)): {'support': 0.10098994092288041,\n",
       "  'confidence': 0.5049900199600799},\n",
       " (('Butter', 'Panner'), ('Ghee',)): {'support': 0.0971579115439885,\n",
       "  'confidence': 0.4901329037454692},\n",
       " (('Butter', 'Milk'), ('Sugar',)): {'support': 0.09875459045186014,\n",
       "  'confidence': 0.49658771577679645},\n",
       " (('Butter', 'Sweet'), ('Sugar',)): {'support': 0.0997125977965831,\n",
       "  'confidence': 0.4911521824616595},\n",
       " (('Sugar', 'Sweet'), ('Butter',)): {'support': 0.0997125977965831,\n",
       "  'confidence': 0.5006012024048097}}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.096\n",
    "min_confidence = 0.49\n",
    "association_rule(min_support, min_confidence, 'GroceryStore.csv', 'Result-2021-03-15 15:47:31.656068.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, entity, parent, count):\n",
    "        self.entity = entity\n",
    "        self.parent_node = parent\n",
    "        self.child_nodes = {}\n",
    "        self.count = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_tree(data, min_support):\n",
    "    one_unique = find_unique_level_one(data, True)\n",
    "    el_one_unique_sorted = support_elimination(data, one_unique, min_support)\n",
    "    node_links = {}\n",
    "    for i in el_one_unique_sorted:\n",
    "        node_links[i] = []\n",
    "    null_node = node(None, None, 1)\n",
    "    for item in data:\n",
    "        item_ordered = sorted(item, key=lambda x: el_one_unique_sorted.index(x))\n",
    "        start_node = null_node\n",
    "        for nd in item_ordered:\n",
    "            if nd in start_node.child_nodes:\n",
    "                start_node.child_nodes[nd].count += 1\n",
    "                start_node = start_node.child_nodes[nd]\n",
    "            else:\n",
    "                this_node = node(nd, start_node, 1)\n",
    "                start_node.child_nodes[nd] = this_node\n",
    "                start_node = this_node\n",
    "                node_links[i].append(this_node) \n",
    "    node_links_sorted = {k: v for k, v in sorted(dct.items(), key=lambda x: el_one_unique_sorted.index(x[0]))}\n",
    "    return (null_node, node_links_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_itemsets(node_links):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_growth(filename, max_length, min_support):\n",
    "    data = read_file(filename)\n",
    "    tree, node_links = fp_tree(data, min_support)\n",
    "    print(tree.child_nodes['Milk'].child_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ghee': <__main__.node object at 0x7fca8aae0850>, 'Bread': <__main__.node object at 0x7fca8aae0fa0>, 'Sweet': <__main__.node object at 0x7fca8c0bf970>, 'Yougurt': <__main__.node object at 0x7fca8c0bfcd0>, 'Coffee Powder': <__main__.node object at 0x7fca8b890130>, 'Sugar': <__main__.node object at 0x7fca8bbf7b50>, 'Butter': <__main__.node object at 0x7fca8bc067c0>, 'Tea Powder': <__main__.node object at 0x7fca8bc0cd60>, 'Cheese': <__main__.node object at 0x7fca8ba54460>, 'Lassi': <__main__.node object at 0x7fca8ba657c0>, 'Panner': <__main__.node object at 0x7fca8ba903a0>}\n"
     ]
    }
   ],
   "source": [
    "fp_growth('GroceryStore.csv', 5, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
