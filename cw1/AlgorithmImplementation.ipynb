{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Butter', 'Cheese', 'Coffee Powder', 'Ghee', 'Lassi', 'Yougurt'], ['Coffee Powder', 'Ghee'], ['Butter', 'Cheese', 'Lassi', 'Tea Powder'], ['Bread', 'Butter', 'Cheese', 'Coffee Powder', 'Panner', 'Tea Powder'], ['Butter', 'Cheese', 'Coffee Powder', 'Sugar', 'Sweet', 'Yougurt']]\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    ds = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        filereader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in filereader:\n",
    "            ds.append(sorted(row[:-1]))\n",
    "        return ds\n",
    "\n",
    "read = read_file('GroceryStore.csv')[:5]\n",
    "print(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',')\n",
    "        for row in data:\n",
    "            filewriter.writerow(row)\n",
    "\n",
    "write_file(read, f'Result-{datetime.datetime.now()}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_elimination(data, items, minimal_support):\n",
    "    lgtn = len(data)\n",
    "    dct = {}\n",
    "    if isinstance(items, set): \n",
    "        for i in items:\n",
    "            dct[i] = 0\n",
    "            for row in data:\n",
    "                if set(i).issubset(set(row)): \n",
    "                    dct[i] = dct[i] + 1\n",
    "            dct[i] = dct[i] / lgtn\n",
    "    else: \n",
    "        for i in items:\n",
    "            dct[i] = 0\n",
    "            for row in data:\n",
    "                if i in row:\n",
    "                    dct[i] = dct[i] + 1\n",
    "            dct[i] = dct[i] / lgtn\n",
    "    support_resistant = []\n",
    "    for key in dct:\n",
    "        if dct[key] >= minimal_support:\n",
    "            support_resistant.append(key)\n",
    "    return support_resistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_level_one(data):\n",
    "    dct = {}\n",
    "    for y in data:\n",
    "        for x in y:\n",
    "            dct[x] = x\n",
    "    return tuple(sorted([i for i in dct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bread',\n",
       " 'Butter',\n",
       " 'Cheese',\n",
       " 'Coffee Powder',\n",
       " 'Ghee',\n",
       " 'Lassi',\n",
       " 'Milk',\n",
       " 'Panner',\n",
       " 'Sugar',\n",
       " 'Sweet',\n",
       " 'Tea Powder',\n",
       " 'Yougurt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_file('GroceryStore.csv')\n",
    "unique = find_unique_level_one(data)\n",
    "support_elimination(data, unique, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_fk1_1(previous_step_f_itemset, step_one_f_itemset):\n",
    "    lst = []\n",
    "    if isinstance(previous_step_f_itemset[0], list) or isinstance(previous_step_f_itemset[0], tuple): \n",
    "        for i in previous_step_f_itemset:\n",
    "            for k in step_one_f_itemset:\n",
    "                if k not in i:\n",
    "                    lst.append(tuple(sorted([*i, k])))\n",
    "    else:\n",
    "        for i in previous_step_f_itemset:\n",
    "            for k in step_one_f_itemset:\n",
    "                if k != i:\n",
    "                    lst.append(tuple(sorted((i, k))))\n",
    "    return set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Bread', 'Butter'),\n",
       " ('Bread', 'Cheese'),\n",
       " ('Bread', 'Coffee Powder'),\n",
       " ('Bread', 'Ghee'),\n",
       " ('Bread', 'Lassi'),\n",
       " ('Bread', 'Milk'),\n",
       " ('Bread', 'Panner'),\n",
       " ('Bread', 'Sugar'),\n",
       " ('Bread', 'Sweet'),\n",
       " ('Bread', 'Tea Powder'),\n",
       " ('Bread', 'Yougurt'),\n",
       " ('Butter', 'Cheese'),\n",
       " ('Butter', 'Coffee Powder'),\n",
       " ('Butter', 'Ghee'),\n",
       " ('Butter', 'Lassi'),\n",
       " ('Butter', 'Milk'),\n",
       " ('Butter', 'Panner'),\n",
       " ('Butter', 'Sugar'),\n",
       " ('Butter', 'Sweet'),\n",
       " ('Butter', 'Tea Powder'),\n",
       " ('Butter', 'Yougurt'),\n",
       " ('Cheese', 'Coffee Powder'),\n",
       " ('Cheese', 'Ghee'),\n",
       " ('Cheese', 'Lassi'),\n",
       " ('Cheese', 'Milk'),\n",
       " ('Cheese', 'Panner'),\n",
       " ('Cheese', 'Sugar'),\n",
       " ('Cheese', 'Sweet'),\n",
       " ('Cheese', 'Tea Powder'),\n",
       " ('Cheese', 'Yougurt'),\n",
       " ('Coffee Powder', 'Ghee'),\n",
       " ('Coffee Powder', 'Lassi'),\n",
       " ('Coffee Powder', 'Milk'),\n",
       " ('Coffee Powder', 'Panner'),\n",
       " ('Coffee Powder', 'Sugar'),\n",
       " ('Coffee Powder', 'Sweet'),\n",
       " ('Coffee Powder', 'Tea Powder'),\n",
       " ('Coffee Powder', 'Yougurt'),\n",
       " ('Ghee', 'Lassi'),\n",
       " ('Ghee', 'Milk'),\n",
       " ('Ghee', 'Panner'),\n",
       " ('Ghee', 'Sugar'),\n",
       " ('Ghee', 'Sweet'),\n",
       " ('Ghee', 'Tea Powder'),\n",
       " ('Ghee', 'Yougurt'),\n",
       " ('Lassi', 'Milk'),\n",
       " ('Lassi', 'Panner'),\n",
       " ('Lassi', 'Sugar'),\n",
       " ('Lassi', 'Sweet'),\n",
       " ('Lassi', 'Tea Powder'),\n",
       " ('Lassi', 'Yougurt'),\n",
       " ('Milk', 'Panner'),\n",
       " ('Milk', 'Sugar'),\n",
       " ('Milk', 'Sweet'),\n",
       " ('Milk', 'Tea Powder'),\n",
       " ('Milk', 'Yougurt'),\n",
       " ('Panner', 'Sugar'),\n",
       " ('Panner', 'Sweet'),\n",
       " ('Panner', 'Tea Powder'),\n",
       " ('Panner', 'Yougurt'),\n",
       " ('Sugar', 'Sweet'),\n",
       " ('Sugar', 'Tea Powder'),\n",
       " ('Sugar', 'Yougurt'),\n",
       " ('Sweet', 'Tea Powder'),\n",
       " ('Sweet', 'Yougurt'),\n",
       " ('Tea Powder', 'Yougurt')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_candidates_fk1_1(unique, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_algorigth(filename, max_length, min_support):\n",
    "    data = read_file(filename)\n",
    "    one_unique = find_unique_level_one(data)\n",
    "    el_one_unique = support_elimination(data, one_unique, min_support)\n",
    "    lim = 1\n",
    "    el_k_unique = el_one_unique\n",
    "    while(lim < max_length):\n",
    "        k_unique = generate_candidates_fk1_1(el_k_unique, el_one_unique)\n",
    "        el_k_unique = support_elimination(data, k_unique, min_support)\n",
    "        lim = lim + 1\n",
    "    return el_k_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = apriori_algorigth('GroceryStore.csv', max_length=4, min_support=0.049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(a, f'Result-{datetime.datetime.now()}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support(itemset, instance):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_condifence(itemset, instance):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sum_pairs(number):\n",
    "    pairs = []\n",
    "    for i in range(1, number):\n",
    "        pairs.append((i, number - i))\n",
    "        pairs.append((number - i, i))\n",
    "    return set(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 9), (2, 8), (3, 7), (4, 6), (5, 5), (6, 4), (7, 3), (8, 2), (9, 1)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sum_pairs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intermediate_list(item, xomb, pivot_idx, pivot_idx_end, is_main):\n",
    "    a = []\n",
    "    for i in range(pivot_idx, pivot_idx_end):\n",
    "        inter = i\n",
    "        length = len(item)\n",
    "        if inter >= length:\n",
    "            inter = inter % length\n",
    "        a.append(item[inter])\n",
    "        if is_main:\n",
    "            if i == pivot_idx_end - 1:\n",
    "                pivot_idx = inter + 1\n",
    "                pivot_idx_end = inter + xomb[1] + 1\n",
    "    if is_main:\n",
    "        return (a, pivot_idx, pivot_idx_end)\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "def generate_combinations(itemset):\n",
    "    combinations = []\n",
    "    for item in itemset:\n",
    "        pairs = generate_sum_pairs(len(item))\n",
    "        for idx, element in enumerate(item):\n",
    "            for xomb in pairs:\n",
    "                pivot_idx = idx\n",
    "                pivot_idx_end = pivot_idx + xomb[0]\n",
    "                ## filling key\n",
    "                a, new_pivot_idx, new_pivot_idx_end = get_intermediate_list(item, xomb, pivot_idx, pivot_idx_end, is_main=True)\n",
    "                ## filling value\n",
    "                b = get_intermediate_list(item, xomb, new_pivot_idx, new_pivot_idx_end, is_main=False)\n",
    "                ## pushing\n",
    "                combinations.append((tuple(a), tuple(b)))\n",
    "    return set(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('Bear',), ('Cat', 'Dog', 'Fox')),\n",
       " (('Bear', 'Cat'), ('Dog', 'Fox')),\n",
       " (('Bear', 'Cat', 'Dog'), ('Fox',)),\n",
       " (('Cat',), ('Dog', 'Fox', 'Bear')),\n",
       " (('Cat', 'Dog'), ('Fox', 'Bear')),\n",
       " (('Cat', 'Dog', 'Fox'), ('Bear',)),\n",
       " (('Dog',), ('Fox', 'Bear', 'Cat')),\n",
       " (('Dog', 'Fox'), ('Bear', 'Cat')),\n",
       " (('Dog', 'Fox', 'Bear'), ('Cat',)),\n",
       " (('Fox',), ('Bear', 'Cat', 'Dog')),\n",
       " (('Fox', 'Bear'), ('Cat', 'Dog')),\n",
       " (('Fox', 'Bear', 'Cat'), ('Dog',))}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset = [['Bear', 'Cat', 'Dog', 'Fox']]\n",
    "generate_combinations(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rule(min_support, min_confidence, file_name):\n",
    "    data = read_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
