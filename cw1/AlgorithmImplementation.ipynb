{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Butter', 'Cheese', 'Coffee Powder', 'Ghee', 'Lassi', 'Yougurt'], ['Coffee Powder', 'Ghee'], ['Butter', 'Cheese', 'Lassi', 'Tea Powder'], ['Bread', 'Butter', 'Cheese', 'Coffee Powder', 'Panner', 'Tea Powder'], ['Butter', 'Cheese', 'Coffee Powder', 'Sugar', 'Sweet', 'Yougurt']]\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    ds = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        filereader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in filereader:\n",
    "            ds.append(sorted(row[:-1]))\n",
    "        return ds\n",
    "\n",
    "read = read_file('GroceryStore.csv')[:5]\n",
    "print(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',')\n",
    "        for row in data:\n",
    "            filewriter.writerow(row)\n",
    "\n",
    "write_file(read, f'Result-{datetime.datetime.now()}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_elimination(data, items, minimal_support):\n",
    "    lgtn = len(data)\n",
    "    dct = {}\n",
    "    if isinstance(items, set): \n",
    "        for i in items:\n",
    "            dct[i] = 0\n",
    "            for row in data:\n",
    "                if set(i).issubset(set(row)): \n",
    "                    dct[i] = dct[i] + 1\n",
    "            dct[i] = dct[i] / lgtn\n",
    "    else: \n",
    "        for i in items:\n",
    "            dct[i] = 0\n",
    "            for row in data:\n",
    "                if i in row:\n",
    "                    dct[i] = dct[i] + 1\n",
    "            dct[i] = dct[i] / lgtn\n",
    "    support_resistant = []\n",
    "    for key in dct:\n",
    "        if dct[key] >= minimal_support:\n",
    "            support_resistant.append(key)\n",
    "    return support_resistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_itemset(data, minimal_support):\n",
    "    support_count = math.ceil(data.length * minimal_support)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associated Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file('GroceryStore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_level_one(data):\n",
    "    dct = {}\n",
    "    for y in data:\n",
    "        for x in y:\n",
    "            dct[x] = x\n",
    "    return tuple(sorted([i for i in dct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bread',\n",
       " 'Butter',\n",
       " 'Cheese',\n",
       " 'Coffee Powder',\n",
       " 'Ghee',\n",
       " 'Lassi',\n",
       " 'Milk',\n",
       " 'Panner',\n",
       " 'Sugar',\n",
       " 'Sweet',\n",
       " 'Tea Powder',\n",
       " 'Yougurt']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = find_unique_level_one(data)\n",
    "support_elimination(data, unique, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_fk1_1(previous_step_f_itemset, step_one_f_itemset):\n",
    "    lst = []\n",
    "    if isinstance(previous_step_f_itemset[0], list) or isinstance(previous_step_f_itemset[0], tuple): \n",
    "        for i in previous_step_f_itemset:\n",
    "            for k in step_one_f_itemset:\n",
    "                if k not in i:\n",
    "                    lst.append(tuple(sorted([*i, k])))\n",
    "    else:\n",
    "        for i in previous_step_f_itemset:\n",
    "            for k in step_one_f_itemset:\n",
    "                if k != i:\n",
    "                    lst.append(tuple(sorted((i, k))))\n",
    "    return set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Bread', 'Butter'),\n",
       " ('Bread', 'Cheese'),\n",
       " ('Bread', 'Coffee Powder'),\n",
       " ('Bread', 'Ghee'),\n",
       " ('Bread', 'Lassi'),\n",
       " ('Bread', 'Milk'),\n",
       " ('Bread', 'Panner'),\n",
       " ('Bread', 'Sugar'),\n",
       " ('Bread', 'Sweet'),\n",
       " ('Bread', 'Tea Powder'),\n",
       " ('Bread', 'Yougurt'),\n",
       " ('Butter', 'Cheese'),\n",
       " ('Butter', 'Coffee Powder'),\n",
       " ('Butter', 'Ghee'),\n",
       " ('Butter', 'Lassi'),\n",
       " ('Butter', 'Milk'),\n",
       " ('Butter', 'Panner'),\n",
       " ('Butter', 'Sugar'),\n",
       " ('Butter', 'Sweet'),\n",
       " ('Butter', 'Tea Powder'),\n",
       " ('Butter', 'Yougurt'),\n",
       " ('Cheese', 'Coffee Powder'),\n",
       " ('Cheese', 'Ghee'),\n",
       " ('Cheese', 'Lassi'),\n",
       " ('Cheese', 'Milk'),\n",
       " ('Cheese', 'Panner'),\n",
       " ('Cheese', 'Sugar'),\n",
       " ('Cheese', 'Sweet'),\n",
       " ('Cheese', 'Tea Powder'),\n",
       " ('Cheese', 'Yougurt'),\n",
       " ('Coffee Powder', 'Ghee'),\n",
       " ('Coffee Powder', 'Lassi'),\n",
       " ('Coffee Powder', 'Milk'),\n",
       " ('Coffee Powder', 'Panner'),\n",
       " ('Coffee Powder', 'Sugar'),\n",
       " ('Coffee Powder', 'Sweet'),\n",
       " ('Coffee Powder', 'Tea Powder'),\n",
       " ('Coffee Powder', 'Yougurt'),\n",
       " ('Ghee', 'Lassi'),\n",
       " ('Ghee', 'Milk'),\n",
       " ('Ghee', 'Panner'),\n",
       " ('Ghee', 'Sugar'),\n",
       " ('Ghee', 'Sweet'),\n",
       " ('Ghee', 'Tea Powder'),\n",
       " ('Ghee', 'Yougurt'),\n",
       " ('Lassi', 'Milk'),\n",
       " ('Lassi', 'Panner'),\n",
       " ('Lassi', 'Sugar'),\n",
       " ('Lassi', 'Sweet'),\n",
       " ('Lassi', 'Tea Powder'),\n",
       " ('Lassi', 'Yougurt'),\n",
       " ('Milk', 'Panner'),\n",
       " ('Milk', 'Sugar'),\n",
       " ('Milk', 'Sweet'),\n",
       " ('Milk', 'Tea Powder'),\n",
       " ('Milk', 'Yougurt'),\n",
       " ('Panner', 'Sugar'),\n",
       " ('Panner', 'Sweet'),\n",
       " ('Panner', 'Tea Powder'),\n",
       " ('Panner', 'Yougurt'),\n",
       " ('Sugar', 'Sweet'),\n",
       " ('Sugar', 'Tea Powder'),\n",
       " ('Sugar', 'Yougurt'),\n",
       " ('Sweet', 'Tea Powder'),\n",
       " ('Sweet', 'Yougurt'),\n",
       " ('Tea Powder', 'Yougurt')}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_candidates_fk1_1(unique, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_algorigth(filename, max_length, min_support):\n",
    "    data = read_file(filename)\n",
    "    one_unique = find_unique_level_one(data)\n",
    "    el_one_unique = support_elimination(data, one_unique, min_support)\n",
    "    lim = 1\n",
    "    el_k_unique = el_one_unique\n",
    "    while(lim < max_length):\n",
    "        k_unique = generate_candidates_fk1_1(el_k_unique, el_one_unique)\n",
    "        el_k_unique = support_elimination(data, k_unique, min_support)\n",
    "        lim = lim + 1\n",
    "    return el_k_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = apriori_algorigth('GroceryStore.csv', max_length=4, min_support=0.049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(a, f'Result-{datetime.datetime.now()}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
